{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_path and group\n",
    "d_path = 'dataset'\n",
    "group = 'test'\n",
    "\n",
    "# Getting dataframe of questions\n",
    "path = '../../exports/%s/other_formats/%s-%s-agqa.csv'\n",
    "path_g = '../../exports/%s/other_formats/%s-%s-agqa-global.csv'\n",
    "df_qs = pd.read_csv(path % (d_path, group, 'balanced'))\n",
    "df_qs_g = pd.read_csv(path_g % (d_path, group, 'balanced'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    'objExists', 'objRelExists', 'relExists', 'actExists', 'andObjRelExists', 'xorObjRelExists',\n",
    "    'objWhatGeneral', 'objWhat', 'objWhatChoose', 'actWhatAfterAll', 'actWhatBefore', 'objFirst', \n",
    "    'objFirstChoose', 'objFirstVerify', 'actFirst', 'objLast', 'objLastChoose', 'objLastVerify', 'actLast', \n",
    "    'actLengthLongerChoose', 'actLengthShorterChoose', 'actLengthLongerVerify', 'actLengthShorterVerify',\n",
    "    'actLongest', 'actShortest', 'actTime', 'relTime', 'objTime'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDic(dic):\n",
    "    if type(dic) != dict:\n",
    "        print(round(dic, 2))\n",
    "    else:\n",
    "        for i in dic:\n",
    "            if type(dic[i]) != dict:\n",
    "                print(' '*4, i, round(dic[i], 2))\n",
    "                \n",
    "            else:\n",
    "                print(' '*4,i)\n",
    "                for j in dic[i]:\n",
    "                    print(' '*8,j, round(dic[i][j], 2))\n",
    "                    \n",
    "        \n",
    "\n",
    "def pathExists(path):\n",
    "    return os.path.exists(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDic(dic, data, cat):\n",
    "    if type(dic) != dict:\n",
    "        data[cat] = round(dic * 100, 2)\n",
    "    else:\n",
    "        \n",
    "        for i in dic:\n",
    "            if type(dic[i]) != dict:\n",
    "                if 'tp' in cat:\n",
    "                    new_cat = '%s-%s' % (cat, i)\n",
    "                    data[new_cat] = round(dic[i] * 100, 2)\n",
    "                    \n",
    "                data[i] = round(dic[i] * 100, 2)\n",
    "            \n",
    "            elif 'tp' in cat:\n",
    "                for j in dic[i]:\n",
    "                    new_cat = '%s-%s' % (i, j)\n",
    "                    data[new_cat] = round(dic[i][j] * 100, 2)\n",
    "            else:\n",
    "                for j in dic[i]:\n",
    "                    print(j)\n",
    "                    data[j] = round(dic[i][j] * 100, 2)\n",
    "                    \n",
    "        \n",
    "                    \n",
    "    return data\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc = 'hcrn'\n",
    "hm = 'hme'\n",
    "p = 'psac'\n",
    "ba = 'balanced'\n",
    "bl = 'blind'\n",
    "c = 'compo'\n",
    "s = 'steps_templ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n",
      "['perc_correct', 'cnt_correct', 'cnt_incorrect', 'size']\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "\n",
    "models = [p, hm, hc]\n",
    "metrics = [bl, ba, c, s]\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for epoch in range(1):\n",
    "            data = {\n",
    "                'model': model,\n",
    "                'metric': metric,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "    \n",
    "            stats_path = '../../exports/%s/results/organized/preds_%s_%s_%s.json' % (d_path, model, metric, epoch)\n",
    "            if pathExists(stats_path):\n",
    "                with open(stats_path, 'rb') as f:\n",
    "                    stats = json.load(f)\n",
    "                    \n",
    "                print(list(stats.keys()))\n",
    "                data['size'] = stats['size']\n",
    "                perc = stats['perc_correct']\n",
    "                \n",
    "                \n",
    "                print(type(stats))\n",
    "                \n",
    "                for i in perc:\n",
    "                    if False:\n",
    "                        if 'tp' in i:\n",
    "                            to_del = []\n",
    "                            to_add = []\n",
    "                            print(i)\n",
    "                            for cat in perc[i]:\n",
    "                                new_cat = '%s-%s' % (i, cat)\n",
    "                                #perc[i][new_cat] = perc[i][cat]\n",
    "\n",
    "                                to_del.append(cat)\n",
    "                                to_add.append((new_cat, perc[i][cat]))\n",
    "                            for cat in to_del:\n",
    "                                del perc[i][cat]\n",
    "                            for new_cat, item in to_add:\n",
    "                                perc[i][new_cat] = item\n",
    "\n",
    "                    if False:\n",
    "                        for i in perc:\n",
    "                            print(i)\n",
    "                            if type(perc[i]) == dict:\n",
    "                                for j in perc[i]:\n",
    "                                    print('.  ', j)\n",
    "                    data = updateDic(perc[i], data, i)\n",
    "                    \n",
    "                    \n",
    "                df_list.append(data)\n",
    "            else:\n",
    "                print(\"NO: %s\" % stats_path)\n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 108)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model', 'metric', 'epoch', 'size', 'total', 'novel_comp',\n",
       "       'novel_comp-tp-binary', 'binary', 'novel_comp-tp-open', 'open',\n",
       "       ...\n",
       "       'duration-comparison-open', 'exists-binary', 'obj-act-binary',\n",
       "       'obj-rel-binary', 'obj-rel-open', 'rel-act-binary', 'sequencing-binary',\n",
       "       'sequencing-open', 'superlative-binary', 'superlative-open'],\n",
       "      dtype='object', length=108)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'rel-act-binary' in list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>epoch</th>\n",
       "      <th>size</th>\n",
       "      <th>total</th>\n",
       "      <th>novel_comp</th>\n",
       "      <th>novel_comp-tp-binary</th>\n",
       "      <th>binary</th>\n",
       "      <th>novel_comp-tp-open</th>\n",
       "      <th>open</th>\n",
       "      <th>...</th>\n",
       "      <th>duration-comparison-binary</th>\n",
       "      <th>duration-comparison-open</th>\n",
       "      <th>exists-binary</th>\n",
       "      <th>obj-act-binary</th>\n",
       "      <th>obj-rel-binary</th>\n",
       "      <th>obj-rel-open</th>\n",
       "      <th>sequencing-binary</th>\n",
       "      <th>sequencing-open</th>\n",
       "      <th>superlative-binary</th>\n",
       "      <th>superlative-open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel-act-binary</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47.74</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47.77</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48.97</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.89</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.90</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.95</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49.98</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.04</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50.56</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  metric  epoch  size  total  novel_comp  \\\n",
       "rel-act-binary                                                  \n",
       "47.74               1       1      1     1      1           1   \n",
       "47.77               1       1      1     1      1           1   \n",
       "48.97               1       1      1     1      1           1   \n",
       "49.86               1       1      1     1      1           1   \n",
       "49.89               1       1      1     1      1           1   \n",
       "49.90               1       1      1     1      1           1   \n",
       "49.95               2       2      2     2      2           2   \n",
       "49.98               1       1      1     1      1           1   \n",
       "50.04               1       1      1     1      1           1   \n",
       "50.10               1       1      1     1      1           1   \n",
       "50.56               1       1      1     1      1           1   \n",
       "\n",
       "                novel_comp-tp-binary  binary  novel_comp-tp-open  open  ...  \\\n",
       "rel-act-binary                                                          ...   \n",
       "47.74                              1       1                   1     1  ...   \n",
       "47.77                              1       1                   1     1  ...   \n",
       "48.97                              1       1                   1     1  ...   \n",
       "49.86                              1       1                   1     1  ...   \n",
       "49.89                              1       1                   1     1  ...   \n",
       "49.90                              1       1                   1     1  ...   \n",
       "49.95                              2       2                   2     2  ...   \n",
       "49.98                              1       1                   1     1  ...   \n",
       "50.04                              1       1                   1     1  ...   \n",
       "50.10                              1       1                   1     1  ...   \n",
       "50.56                              1       1                   1     1  ...   \n",
       "\n",
       "                duration-comparison-binary  duration-comparison-open  \\\n",
       "rel-act-binary                                                         \n",
       "47.74                                    1                         1   \n",
       "47.77                                    1                         1   \n",
       "48.97                                    1                         1   \n",
       "49.86                                    1                         1   \n",
       "49.89                                    0                         0   \n",
       "49.90                                    1                         1   \n",
       "49.95                                    2                         2   \n",
       "49.98                                    1                         1   \n",
       "50.04                                    1                         1   \n",
       "50.10                                    0                         0   \n",
       "50.56                                    0                         0   \n",
       "\n",
       "                exists-binary  obj-act-binary  obj-rel-binary  obj-rel-open  \\\n",
       "rel-act-binary                                                                \n",
       "47.74                       1               1               1             1   \n",
       "47.77                       1               1               1             1   \n",
       "48.97                       1               1               1             1   \n",
       "49.86                       1               1               1             1   \n",
       "49.89                       1               1               1             1   \n",
       "49.90                       1               1               1             1   \n",
       "49.95                       2               2               2             2   \n",
       "49.98                       1               1               1             1   \n",
       "50.04                       1               1               1             1   \n",
       "50.10                       1               1               1             1   \n",
       "50.56                       1               1               1             1   \n",
       "\n",
       "                sequencing-binary  sequencing-open  superlative-binary  \\\n",
       "rel-act-binary                                                           \n",
       "47.74                           1                1                   1   \n",
       "47.77                           1                1                   1   \n",
       "48.97                           1                1                   1   \n",
       "49.86                           1                1                   1   \n",
       "49.89                           1                1                   1   \n",
       "49.90                           1                1                   1   \n",
       "49.95                           2                2                   2   \n",
       "49.98                           1                1                   1   \n",
       "50.04                           1                1                   1   \n",
       "50.10                           1                1                   1   \n",
       "50.56                           1                1                   1   \n",
       "\n",
       "                superlative-open  \n",
       "rel-act-binary                    \n",
       "47.74                          1  \n",
       "47.77                          1  \n",
       "48.97                          1  \n",
       "49.86                          1  \n",
       "49.89                          1  \n",
       "49.90                          1  \n",
       "49.95                          2  \n",
       "49.98                          1  \n",
       "50.04                          1  \n",
       "50.10                          1  \n",
       "50.56                          1  \n",
       "\n",
       "[11 rows x 107 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('rel-act-binary').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>epoch</th>\n",
       "      <th>total</th>\n",
       "      <th>direct_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>psac</td>\n",
       "      <td>blind</td>\n",
       "      <td>0</td>\n",
       "      <td>40.26</td>\n",
       "      <td>86.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>psac</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0</td>\n",
       "      <td>40.18</td>\n",
       "      <td>88.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>psac</td>\n",
       "      <td>compo</td>\n",
       "      <td>0</td>\n",
       "      <td>34.71</td>\n",
       "      <td>87.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>psac</td>\n",
       "      <td>steps_templ</td>\n",
       "      <td>0</td>\n",
       "      <td>47.19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hme</td>\n",
       "      <td>blind</td>\n",
       "      <td>0</td>\n",
       "      <td>39.03</td>\n",
       "      <td>86.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hme</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0</td>\n",
       "      <td>39.89</td>\n",
       "      <td>86.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hme</td>\n",
       "      <td>compo</td>\n",
       "      <td>0</td>\n",
       "      <td>33.15</td>\n",
       "      <td>86.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hme</td>\n",
       "      <td>steps_templ</td>\n",
       "      <td>0</td>\n",
       "      <td>47.72</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hcrn</td>\n",
       "      <td>blind</td>\n",
       "      <td>0</td>\n",
       "      <td>40.19</td>\n",
       "      <td>81.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hcrn</td>\n",
       "      <td>balanced</td>\n",
       "      <td>0</td>\n",
       "      <td>42.11</td>\n",
       "      <td>89.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hcrn</td>\n",
       "      <td>compo</td>\n",
       "      <td>0</td>\n",
       "      <td>34.13</td>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hcrn</td>\n",
       "      <td>steps_templ</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model       metric  epoch  total  direct_correct\n",
       "0   psac        blind      0  40.26           86.31\n",
       "1   psac     balanced      0  40.18           88.34\n",
       "2   psac        compo      0  34.71           87.41\n",
       "3   psac  steps_templ      0  47.19            0.00\n",
       "4    hme        blind      0  39.03           86.38\n",
       "5    hme     balanced      0  39.89           86.17\n",
       "6    hme        compo      0  33.15           86.85\n",
       "7    hme  steps_templ      0  47.72            0.00\n",
       "8   hcrn        blind      0  40.19           81.35\n",
       "9   hcrn     balanced      0  42.11           89.47\n",
       "10  hcrn        compo      0  34.13           80.62\n",
       "11  hcrn  steps_templ      0  46.63            0.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['model', 'metric', 'epoch', 'total', 'direct_correct']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# brainstorm why blind is doing so well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = df[(df['metric'] == 'blind') | (df['metric'] == 'balanced')]\n",
    "#cols = ['epoch'] + base + glob + sem + struct + total \n",
    "\n",
    "#data = data[cols]\n",
    "\n",
    "#data = data.transpose()\n",
    "\n",
    "#csv(data, '2-blind-psac-epochs')\n",
    "\n",
    "#data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make csv files of results\n",
    "\n",
    "Todo\n",
    "- most-likely baseline\n",
    "- to_direct -- rouble check if correct\n",
    "    - its not... i think. I need to make it so that it's how many when the direct is correct, they are correct. still TODO\n",
    "- figure 5, split by open/binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv(item, title):\n",
    "    path = '../../exports/dataset/results/csv/%s.csv' % title\n",
    "    item.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = ['model', 'metric']\n",
    "glob = ['obj-rel', 'rel-act', 'obj-act', 'superlative', 'sequencing', 'exists', 'duration-comparison', 'action-recognition']\n",
    "sem = ['object', 'relation', 'action']\n",
    "struct = ['query', 'compare', 'choose', 'logic', 'verify']\n",
    "total = ['binary', 'open', 'total']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAPTED for how im missing shit\n",
    "base = ['model', 'metric']\n",
    "glob = ['obj-rel', 'obj-act', 'superlative', 'sequencing', 'exists', 'duration-comparison', 'action-recognition']\n",
    "sem = ['object', 'relation', 'action']\n",
    "struct = ['query', 'compare', 'choose', 'logic', 'verify']\n",
    "total = ['binary', 'open', 'total']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-rel</th>\n",
       "      <td>37.84</td>\n",
       "      <td>37.42</td>\n",
       "      <td>40.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-act</th>\n",
       "      <td>50</td>\n",
       "      <td>49.97</td>\n",
       "      <td>49.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superlative</th>\n",
       "      <td>33.2</td>\n",
       "      <td>33.21</td>\n",
       "      <td>33.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequencing</th>\n",
       "      <td>49.78</td>\n",
       "      <td>49.77</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exists</th>\n",
       "      <td>49.94</td>\n",
       "      <td>49.96</td>\n",
       "      <td>50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration-comparison</th>\n",
       "      <td>45.21</td>\n",
       "      <td>47.03</td>\n",
       "      <td>43.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action-recognition</th>\n",
       "      <td>4.14</td>\n",
       "      <td>5.43</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>37.97</td>\n",
       "      <td>37.55</td>\n",
       "      <td>40.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <td>49.95</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>46.85</td>\n",
       "      <td>47.58</td>\n",
       "      <td>46.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>31.63</td>\n",
       "      <td>31.01</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compare</th>\n",
       "      <td>49.49</td>\n",
       "      <td>49.71</td>\n",
       "      <td>49.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choose</th>\n",
       "      <td>46.56</td>\n",
       "      <td>46.42</td>\n",
       "      <td>43.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>49.96</td>\n",
       "      <td>49.87</td>\n",
       "      <td>50.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify</th>\n",
       "      <td>49.9</td>\n",
       "      <td>49.96</td>\n",
       "      <td>50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>48.87</td>\n",
       "      <td>48.91</td>\n",
       "      <td>47.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>31.63</td>\n",
       "      <td>31.01</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>40.18</td>\n",
       "      <td>39.89</td>\n",
       "      <td>42.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            1         5         9\n",
       "model                    psac       hme      hcrn\n",
       "metric               balanced  balanced  balanced\n",
       "obj-rel                 37.84     37.42     40.33\n",
       "obj-act                    50     49.97     49.85\n",
       "superlative              33.2     33.21     33.55\n",
       "sequencing              49.78     49.77      49.7\n",
       "exists                  49.94     49.96     50.01\n",
       "duration-comparison     45.21     47.03     43.84\n",
       "action-recognition       4.14      5.43      5.52\n",
       "object                  37.97     37.55      40.4\n",
       "relation                49.95     49.99     49.96\n",
       "action                  46.85     47.58     46.41\n",
       "query                   31.63     31.01     36.34\n",
       "compare                 49.49     49.71     49.22\n",
       "choose                  46.56     46.42     43.42\n",
       "logic                   49.96     49.87     50.02\n",
       "verify                   49.9     49.96     50.01\n",
       "binary                  48.87     48.91     47.97\n",
       "open                    31.63     31.01     36.34\n",
       "total                   40.18     39.89     42.11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'balanced')]\n",
    "cols = base + glob + sem + struct + total\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '2-balanced')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2 with blind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>blind</td>\n",
       "      <td>balanced</td>\n",
       "      <td>blind</td>\n",
       "      <td>balanced</td>\n",
       "      <td>blind</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-rel</th>\n",
       "      <td>37.91</td>\n",
       "      <td>37.84</td>\n",
       "      <td>36.44</td>\n",
       "      <td>37.42</td>\n",
       "      <td>37.9</td>\n",
       "      <td>40.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-act</th>\n",
       "      <td>50.01</td>\n",
       "      <td>50</td>\n",
       "      <td>50.09</td>\n",
       "      <td>49.97</td>\n",
       "      <td>50</td>\n",
       "      <td>49.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superlative</th>\n",
       "      <td>33.59</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.53</td>\n",
       "      <td>33.21</td>\n",
       "      <td>33.4</td>\n",
       "      <td>33.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequencing</th>\n",
       "      <td>49.78</td>\n",
       "      <td>49.78</td>\n",
       "      <td>49.79</td>\n",
       "      <td>49.77</td>\n",
       "      <td>49.78</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exists</th>\n",
       "      <td>50.04</td>\n",
       "      <td>49.94</td>\n",
       "      <td>50.02</td>\n",
       "      <td>49.96</td>\n",
       "      <td>49.96</td>\n",
       "      <td>50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration-comparison</th>\n",
       "      <td>45.77</td>\n",
       "      <td>45.21</td>\n",
       "      <td>42.67</td>\n",
       "      <td>47.03</td>\n",
       "      <td>43.12</td>\n",
       "      <td>43.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action-recognition</th>\n",
       "      <td>4.88</td>\n",
       "      <td>4.14</td>\n",
       "      <td>6.53</td>\n",
       "      <td>5.43</td>\n",
       "      <td>2.58</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>38.03</td>\n",
       "      <td>37.97</td>\n",
       "      <td>36.58</td>\n",
       "      <td>37.55</td>\n",
       "      <td>38.04</td>\n",
       "      <td>40.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <td>50.04</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.05</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>47.07</td>\n",
       "      <td>46.85</td>\n",
       "      <td>45.84</td>\n",
       "      <td>47.58</td>\n",
       "      <td>45.98</td>\n",
       "      <td>46.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>31.63</td>\n",
       "      <td>31.63</td>\n",
       "      <td>29.52</td>\n",
       "      <td>31.01</td>\n",
       "      <td>31.57</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compare</th>\n",
       "      <td>49.57</td>\n",
       "      <td>49.49</td>\n",
       "      <td>49.16</td>\n",
       "      <td>49.71</td>\n",
       "      <td>49.22</td>\n",
       "      <td>49.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choose</th>\n",
       "      <td>46.87</td>\n",
       "      <td>46.56</td>\n",
       "      <td>46.12</td>\n",
       "      <td>46.42</td>\n",
       "      <td>47.08</td>\n",
       "      <td>43.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>50.09</td>\n",
       "      <td>49.96</td>\n",
       "      <td>50.17</td>\n",
       "      <td>49.87</td>\n",
       "      <td>50.07</td>\n",
       "      <td>50.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify</th>\n",
       "      <td>49.97</td>\n",
       "      <td>49.9</td>\n",
       "      <td>49.93</td>\n",
       "      <td>49.96</td>\n",
       "      <td>49.92</td>\n",
       "      <td>50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>49.01</td>\n",
       "      <td>48.87</td>\n",
       "      <td>48.68</td>\n",
       "      <td>48.91</td>\n",
       "      <td>48.95</td>\n",
       "      <td>47.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>31.63</td>\n",
       "      <td>31.63</td>\n",
       "      <td>29.52</td>\n",
       "      <td>31.01</td>\n",
       "      <td>31.57</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>40.26</td>\n",
       "      <td>40.18</td>\n",
       "      <td>39.03</td>\n",
       "      <td>39.89</td>\n",
       "      <td>40.19</td>\n",
       "      <td>42.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0         1      4         5      8         9\n",
       "model                 psac      psac    hme       hme   hcrn      hcrn\n",
       "metric               blind  balanced  blind  balanced  blind  balanced\n",
       "obj-rel              37.91     37.84  36.44     37.42   37.9     40.33\n",
       "obj-act              50.01        50  50.09     49.97     50     49.85\n",
       "superlative          33.59      33.2  32.53     33.21   33.4     33.55\n",
       "sequencing           49.78     49.78  49.79     49.77  49.78      49.7\n",
       "exists               50.04     49.94  50.02     49.96  49.96     50.01\n",
       "duration-comparison  45.77     45.21  42.67     47.03  43.12     43.84\n",
       "action-recognition    4.88      4.14   6.53      5.43   2.58      5.52\n",
       "object               38.03     37.97  36.58     37.55  38.04      40.4\n",
       "relation             50.04     49.95  50.05     49.99  49.98     49.96\n",
       "action               47.07     46.85  45.84     47.58  45.98     46.41\n",
       "query                31.63     31.63  29.52     31.01  31.57     36.34\n",
       "compare              49.57     49.49  49.16     49.71  49.22     49.22\n",
       "choose               46.87     46.56  46.12     46.42  47.08     43.42\n",
       "logic                50.09     49.96  50.17     49.87  50.07     50.02\n",
       "verify               49.97      49.9  49.93     49.96  49.92     50.01\n",
       "binary               49.01     48.87  48.68     48.91  48.95     47.97\n",
       "open                 31.63     31.63  29.52     31.01  31.57     36.34\n",
       "total                40.26     40.18  39.03     39.89  40.19     42.11"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'blind') | (df['metric'] == 'balanced')]\n",
    "cols = base + glob + sem + struct + total\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '2-blind')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>compo</td>\n",
       "      <td>compo</td>\n",
       "      <td>compo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>46.49</td>\n",
       "      <td>45.42</td>\n",
       "      <td>44.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>19.34</td>\n",
       "      <td>17.17</td>\n",
       "      <td>20.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>34.71</td>\n",
       "      <td>33.15</td>\n",
       "      <td>34.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           2      6      10\n",
       "model    psac    hme   hcrn\n",
       "metric  compo  compo  compo\n",
       "binary  46.49  45.42  44.88\n",
       "open    19.34  17.17  20.12\n",
       "total   34.71  33.15  34.13"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'compo')]\n",
    "cols = base + total\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '3-compo')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>steps_templ</td>\n",
       "      <td>steps_templ</td>\n",
       "      <td>steps_templ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>47.65</td>\n",
       "      <td>48.09</td>\n",
       "      <td>46.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>14.81</td>\n",
       "      <td>20.98</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>47.19</td>\n",
       "      <td>47.72</td>\n",
       "      <td>46.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 3            7            11\n",
       "model          psac          hme         hcrn\n",
       "metric  steps_templ  steps_templ  steps_templ\n",
       "binary        47.65        48.09        46.96\n",
       "open          14.81        20.98         23.7\n",
       "total         47.19        47.72        46.63"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'steps_templ')]\n",
    "cols = base + total\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '3-steps')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_seq</th>\n",
       "      <td>40.96</td>\n",
       "      <td>40.53</td>\n",
       "      <td>40.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_sup</th>\n",
       "      <td>33.32</td>\n",
       "      <td>30.95</td>\n",
       "      <td>33.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_dur</th>\n",
       "      <td>42.06</td>\n",
       "      <td>42.31</td>\n",
       "      <td>43.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_objrel</th>\n",
       "      <td>24.28</td>\n",
       "      <td>21.96</td>\n",
       "      <td>21.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              2      6      10\n",
       "model       psac    hme   hcrn\n",
       "nc_seq     40.96  40.53  40.73\n",
       "nc_sup     33.32  30.95  33.06\n",
       "nc_dur     42.06  42.31  43.01\n",
       "nc_objrel  24.28  21.96  21.88"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'compo')]\n",
    "cols = ['model', 'nc_seq', 'nc_sup', 'nc_dur', 'nc_objrel']\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '4')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2</th>\n",
       "      <th>6</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_seq-tp-binary</th>\n",
       "      <td>49.19</td>\n",
       "      <td>49.33</td>\n",
       "      <td>48.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_seq-tp-open</th>\n",
       "      <td>29.33</td>\n",
       "      <td>28.06</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_seq</th>\n",
       "      <td>40.96</td>\n",
       "      <td>40.53</td>\n",
       "      <td>40.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_sup-tp-binary</th>\n",
       "      <td>45.23</td>\n",
       "      <td>44.06</td>\n",
       "      <td>45.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_sup-tp-open</th>\n",
       "      <td>17.76</td>\n",
       "      <td>13.8</td>\n",
       "      <td>17.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_sup</th>\n",
       "      <td>33.32</td>\n",
       "      <td>30.95</td>\n",
       "      <td>33.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_dur-tp-binary</th>\n",
       "      <td>47.89</td>\n",
       "      <td>48.45</td>\n",
       "      <td>46.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_dur-tp-open</th>\n",
       "      <td>34.84</td>\n",
       "      <td>34.72</td>\n",
       "      <td>39.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_dur</th>\n",
       "      <td>42.06</td>\n",
       "      <td>42.31</td>\n",
       "      <td>43.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_objrel-tp-binary</th>\n",
       "      <td>43.76</td>\n",
       "      <td>39.58</td>\n",
       "      <td>37.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_objrel-tp-open</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>2.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nc_objrel</th>\n",
       "      <td>24.28</td>\n",
       "      <td>21.96</td>\n",
       "      <td>21.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        2      6      10\n",
       "model                 psac    hme   hcrn\n",
       "nc_seq-tp-binary     49.19  49.33  48.31\n",
       "nc_seq-tp-open       29.33  28.06     30\n",
       "nc_seq               40.96  40.53  40.73\n",
       "nc_sup-tp-binary     45.23  44.06  45.12\n",
       "nc_sup-tp-open       17.76   13.8   17.3\n",
       "nc_sup               33.32  30.95  33.06\n",
       "nc_dur-tp-binary     47.89  48.45  46.15\n",
       "nc_dur-tp-open       34.84  34.72  39.11\n",
       "nc_dur               42.06  42.31  43.01\n",
       "nc_objrel-tp-binary  43.76  39.58  37.15\n",
       "nc_objrel-tp-open     0.01      0   2.86\n",
       "nc_objrel            24.28  21.96  21.88"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'compo')]\n",
    "cols = ['model', 'nc_seq-tp-binary','nc_seq-tp-open','nc_seq', 'nc_sup-tp-binary', 'nc_sup-tp-open', 'nc_sup', 'nc_dur-tp-binary', 'nc_dur-tp-open', 'nc_dur', 'nc_objrel-tp-binary', 'nc_objrel-tp-open', 'nc_objrel']\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '6')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>7</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>steps_templ</td>\n",
       "      <td>steps_templ</td>\n",
       "      <td>steps_templ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>47.65</td>\n",
       "      <td>48.09</td>\n",
       "      <td>46.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>14.81</td>\n",
       "      <td>20.98</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>47.19</td>\n",
       "      <td>47.72</td>\n",
       "      <td>46.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 3            7            11\n",
       "model          psac          hme         hcrn\n",
       "metric  steps_templ  steps_templ  steps_templ\n",
       "binary        47.65        48.09        46.96\n",
       "open          14.81        20.98         23.7\n",
       "total         47.19        47.72        46.63"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'steps_templ')]\n",
    "cols = base + total\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '8')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_tp = ['obj-rel-binary', 'obj-rel-open', 'obj-rel', 'rel-act-binary', 'obj-act-binary', 'superlative-binary', 'superlative-open', 'superlative', 'sequencing-binary', 'sequencing-open', 'sequencing', 'exists-binary', 'duration-comparison-binary', 'duration-comparison-open', 'duration-comparison', 'action-recognition-open']\n",
    "sem_tp = ['object-binary', 'object-open', 'object', 'relation-binary', 'action-binary', 'action-open', 'action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FOR WHEN IM MISSING SHIT LIKE RELACT\n",
    "\n",
    "#glob_tp = ['obj-rel-binary', 'obj-rel-open', 'obj-rel', 'obj-act-binary', 'superlative-binary', 'superlative-open', 'superlative', 'sequencing-binary', 'sequencing-open', 'sequencing', 'exists-binary', 'duration-comparison-binary', 'duration-comparison-open', 'duration-comparison', 'action-recognition-open']\n",
    "#sem_tp = ['object-binary', 'object-open', 'object', 'relation-binary', 'action-binary', 'action-open', 'action']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>psac</td>\n",
       "      <td>psac</td>\n",
       "      <td>hme</td>\n",
       "      <td>hme</td>\n",
       "      <td>hcrn</td>\n",
       "      <td>hcrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <td>blind</td>\n",
       "      <td>balanced</td>\n",
       "      <td>blind</td>\n",
       "      <td>balanced</td>\n",
       "      <td>blind</td>\n",
       "      <td>balanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-rel-binary</th>\n",
       "      <td>48.49</td>\n",
       "      <td>48.3</td>\n",
       "      <td>48.13</td>\n",
       "      <td>48.24</td>\n",
       "      <td>48.57</td>\n",
       "      <td>46.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-rel-open</th>\n",
       "      <td>31.91</td>\n",
       "      <td>31.91</td>\n",
       "      <td>29.81</td>\n",
       "      <td>31.29</td>\n",
       "      <td>31.85</td>\n",
       "      <td>36.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-rel</th>\n",
       "      <td>37.91</td>\n",
       "      <td>37.84</td>\n",
       "      <td>36.44</td>\n",
       "      <td>37.42</td>\n",
       "      <td>37.9</td>\n",
       "      <td>40.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rel-act-binary</th>\n",
       "      <td>49.95</td>\n",
       "      <td>49.95</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.9</td>\n",
       "      <td>50.04</td>\n",
       "      <td>49.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>obj-act-binary</th>\n",
       "      <td>50.01</td>\n",
       "      <td>50</td>\n",
       "      <td>50.09</td>\n",
       "      <td>49.97</td>\n",
       "      <td>50</td>\n",
       "      <td>49.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superlative-binary</th>\n",
       "      <td>50.36</td>\n",
       "      <td>50.25</td>\n",
       "      <td>50.44</td>\n",
       "      <td>50.82</td>\n",
       "      <td>50.77</td>\n",
       "      <td>49.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superlative-open</th>\n",
       "      <td>17.57</td>\n",
       "      <td>16.92</td>\n",
       "      <td>15.42</td>\n",
       "      <td>16.39</td>\n",
       "      <td>16.82</td>\n",
       "      <td>18.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superlative</th>\n",
       "      <td>33.59</td>\n",
       "      <td>33.2</td>\n",
       "      <td>32.53</td>\n",
       "      <td>33.21</td>\n",
       "      <td>33.4</td>\n",
       "      <td>33.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequencing-binary</th>\n",
       "      <td>49.98</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.96</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequencing-open</th>\n",
       "      <td>5.04</td>\n",
       "      <td>5.54</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.55</td>\n",
       "      <td>3.53</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sequencing</th>\n",
       "      <td>49.78</td>\n",
       "      <td>49.78</td>\n",
       "      <td>49.79</td>\n",
       "      <td>49.77</td>\n",
       "      <td>49.78</td>\n",
       "      <td>49.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exists-binary</th>\n",
       "      <td>50.04</td>\n",
       "      <td>49.94</td>\n",
       "      <td>50.02</td>\n",
       "      <td>49.96</td>\n",
       "      <td>49.96</td>\n",
       "      <td>50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration-comparison-binary</th>\n",
       "      <td>46.76</td>\n",
       "      <td>46.18</td>\n",
       "      <td>43.6</td>\n",
       "      <td>48.01</td>\n",
       "      <td>44.02</td>\n",
       "      <td>44.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration-comparison-open</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.93</td>\n",
       "      <td>3.28</td>\n",
       "      <td>5.57</td>\n",
       "      <td>4.92</td>\n",
       "      <td>8.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration-comparison</th>\n",
       "      <td>45.77</td>\n",
       "      <td>45.21</td>\n",
       "      <td>42.67</td>\n",
       "      <td>47.03</td>\n",
       "      <td>43.12</td>\n",
       "      <td>43.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action-recognition-open</th>\n",
       "      <td>4.88</td>\n",
       "      <td>4.14</td>\n",
       "      <td>6.53</td>\n",
       "      <td>5.43</td>\n",
       "      <td>2.58</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object-binary</th>\n",
       "      <td>48.56</td>\n",
       "      <td>48.4</td>\n",
       "      <td>48.23</td>\n",
       "      <td>48.32</td>\n",
       "      <td>48.66</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object-open</th>\n",
       "      <td>31.74</td>\n",
       "      <td>31.74</td>\n",
       "      <td>29.62</td>\n",
       "      <td>31.11</td>\n",
       "      <td>31.69</td>\n",
       "      <td>36.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>38.03</td>\n",
       "      <td>37.97</td>\n",
       "      <td>36.58</td>\n",
       "      <td>37.55</td>\n",
       "      <td>38.04</td>\n",
       "      <td>40.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation-binary</th>\n",
       "      <td>50.04</td>\n",
       "      <td>49.95</td>\n",
       "      <td>50.05</td>\n",
       "      <td>49.99</td>\n",
       "      <td>49.98</td>\n",
       "      <td>49.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action-binary</th>\n",
       "      <td>48.77</td>\n",
       "      <td>48.56</td>\n",
       "      <td>47.45</td>\n",
       "      <td>49.27</td>\n",
       "      <td>47.71</td>\n",
       "      <td>48.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action-open</th>\n",
       "      <td>4.6</td>\n",
       "      <td>4.09</td>\n",
       "      <td>5.82</td>\n",
       "      <td>5.46</td>\n",
       "      <td>3.09</td>\n",
       "      <td>6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>action</th>\n",
       "      <td>47.07</td>\n",
       "      <td>46.85</td>\n",
       "      <td>45.84</td>\n",
       "      <td>47.58</td>\n",
       "      <td>45.98</td>\n",
       "      <td>46.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <td>31.63</td>\n",
       "      <td>31.63</td>\n",
       "      <td>29.52</td>\n",
       "      <td>31.01</td>\n",
       "      <td>31.57</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>compare</th>\n",
       "      <td>49.57</td>\n",
       "      <td>49.49</td>\n",
       "      <td>49.16</td>\n",
       "      <td>49.71</td>\n",
       "      <td>49.22</td>\n",
       "      <td>49.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>choose</th>\n",
       "      <td>46.87</td>\n",
       "      <td>46.56</td>\n",
       "      <td>46.12</td>\n",
       "      <td>46.42</td>\n",
       "      <td>47.08</td>\n",
       "      <td>43.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logic</th>\n",
       "      <td>50.09</td>\n",
       "      <td>49.96</td>\n",
       "      <td>50.17</td>\n",
       "      <td>49.87</td>\n",
       "      <td>50.07</td>\n",
       "      <td>50.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verify</th>\n",
       "      <td>49.97</td>\n",
       "      <td>49.9</td>\n",
       "      <td>49.93</td>\n",
       "      <td>49.96</td>\n",
       "      <td>49.92</td>\n",
       "      <td>50.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>binary</th>\n",
       "      <td>49.01</td>\n",
       "      <td>48.87</td>\n",
       "      <td>48.68</td>\n",
       "      <td>48.91</td>\n",
       "      <td>48.95</td>\n",
       "      <td>47.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>open</th>\n",
       "      <td>31.63</td>\n",
       "      <td>31.63</td>\n",
       "      <td>29.52</td>\n",
       "      <td>31.01</td>\n",
       "      <td>31.57</td>\n",
       "      <td>36.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>40.26</td>\n",
       "      <td>40.18</td>\n",
       "      <td>39.03</td>\n",
       "      <td>39.89</td>\n",
       "      <td>40.19</td>\n",
       "      <td>42.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0         1      4         5      8         9\n",
       "model                        psac      psac    hme       hme   hcrn      hcrn\n",
       "metric                      blind  balanced  blind  balanced  blind  balanced\n",
       "obj-rel-binary              48.49      48.3  48.13     48.24  48.57     46.83\n",
       "obj-rel-open                31.91     31.91  29.81     31.29  31.85     36.65\n",
       "obj-rel                     37.91     37.84  36.44     37.42   37.9     40.33\n",
       "rel-act-binary              49.95     49.95  49.98      49.9  50.04     49.86\n",
       "obj-act-binary              50.01        50  50.09     49.97     50     49.85\n",
       "superlative-binary          50.36     50.25  50.44     50.82  50.77     49.76\n",
       "superlative-open            17.57     16.92  15.42     16.39  16.82     18.08\n",
       "superlative                 33.59      33.2  32.53     33.21   33.4     33.55\n",
       "sequencing-binary           49.98     49.98  49.98     49.96  49.99     49.89\n",
       "sequencing-open              5.04      5.54    7.3      6.55   3.53       7.3\n",
       "sequencing                  49.78     49.78  49.79     49.77  49.78      49.7\n",
       "exists-binary               50.04     49.94  50.02     49.96  49.96     50.01\n",
       "duration-comparison-binary  46.76     46.18   43.6     48.01  44.02     44.66\n",
       "duration-comparison-open     3.61      3.93   3.28      5.57   4.92      8.85\n",
       "duration-comparison         45.77     45.21  42.67     47.03  43.12     43.84\n",
       "action-recognition-open      4.88      4.14   6.53      5.43   2.58      5.52\n",
       "object-binary               48.56      48.4  48.23     48.32  48.66        47\n",
       "object-open                 31.74     31.74  29.62     31.11  31.69     36.46\n",
       "object                      38.03     37.97  36.58     37.55  38.04      40.4\n",
       "relation-binary             50.04     49.95  50.05     49.99  49.98     49.96\n",
       "action-binary               48.77     48.56  47.45     49.27  47.71     48.02\n",
       "action-open                   4.6      4.09   5.82      5.46   3.09      6.25\n",
       "action                      47.07     46.85  45.84     47.58  45.98     46.41\n",
       "query                       31.63     31.63  29.52     31.01  31.57     36.34\n",
       "compare                     49.57     49.49  49.16     49.71  49.22     49.22\n",
       "choose                      46.87     46.56  46.12     46.42  47.08     43.42\n",
       "logic                       50.09     49.96  50.17     49.87  50.07     50.02\n",
       "verify                      49.97      49.9  49.93     49.96  49.92     50.01\n",
       "binary                      49.01     48.87  48.68     48.91  48.95     47.97\n",
       "open                        31.63     31.63  29.52     31.01  31.57     36.34\n",
       "total                       40.26     40.18  39.03     39.89  40.19     42.11"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[(df['metric'] == 'blind') | (df['metric'] == 'balanced')]\n",
    "cols = base + glob_tp + sem_tp + struct + total\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, '9')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['steps'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-4e37dd5c4944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2804\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m         self._validate_read_indexer(\n\u001b[0;32m-> 1552\u001b[0;31m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1553\u001b[0m         )\n\u001b[1;32m   1554\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['steps'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "data = df[df['metric'] == 'balanced']\n",
    "cols = ['steps']\n",
    "\n",
    "data = data[cols]\n",
    "\n",
    "data = data.transpose()\n",
    "\n",
    "csv(data, 'steps')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables using preds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreds(d_path, model, metric, epoch, glob=False):\n",
    "    if glob:\n",
    "        preds_path = '../../exports/%s/results/organized/preds_%s_%s_%s-preds_g.csv' % (d_path, model, metric, epoch)\n",
    "    else:\n",
    "        preds_path = '../../exports/%s/results/organized/preds_%s_%s_%s-preds.csv' % (d_path, model, metric, epoch)\n",
    "        \n",
    "        \n",
    "    return pd.read_csv(preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "models = [p, hm, hc]\n",
    "metrics = [bl, ba, c, s]\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for epoch in range(1):\n",
    "            preds = getPreds('dataset', model, metric, epoch)\n",
    "            preds['model'] = model\n",
    "            preds['metric'] = metric\n",
    "            preds['epoch'] = epoch\n",
    "            df = df.append(preds)\n",
    "            print('preds shape', preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df['metric'] == 'balanced']\n",
    "bal = df[df['metric'] == 'balanced']\n",
    "compo = df[df['metric'] == 'compo']\n",
    "steps = df[df['metric'] == 'steps_templ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First find recall. This is the percent of questions that are correct are correct. \n",
    "# step 1, split by i_obj, i_act, i_temp\n",
    "obj = data[data['i_obj'] == 1]\n",
    "act = data[data['i_act'] == 1]\n",
    "tem = data[data['i_temp'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# step 2: find the direct_equivs for all\n",
    "obj_de_idx = obj['direct_equiv'].values\n",
    "act_de_idx = act['direct_equiv'].values\n",
    "tem_de_idx = tem['direct_equiv'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: get all direct questions\n",
    "obj_de = data[data['id'].isin(obj_de_idx)]\n",
    "act_de = data[data['id'].isin(act_de_idx)]\n",
    "tem_de = data[data['id'].isin(tem_de_idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4: find accuracy of direct questions\n",
    "print('RECALL: ')\n",
    "print('object: ', obj_de['correct'].mean())\n",
    "print('action: ', act_de['correct'].mean())\n",
    "print('temloc: ', tem_de['correct'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRECISION\n",
    "# step 1: get direct equivs that are correct. \n",
    "cor_obj_de = obj_de[obj_de['correct'] == 1]['id'].values\n",
    "cor_act_de = act_de[act_de['correct'] == 1]['id'].values\n",
    "cor_tem_de = tem_de[tem_de['correct'] == 1]['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: get all things wwhere direct equiv is in that list\n",
    "obj_ind = data[data['direct_equiv'].isin(cor_obj_de)]\n",
    "act_ind = data[data['direct_equiv'].isin(cor_act_de)]\n",
    "tem_ind = data[data['direct_equiv'].isin(cor_tem_de)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: delete ones with no indirect\n",
    "obj_ind = obj_ind[obj_ind['indirect'] == 1]\n",
    "act_ind = act_ind[act_ind['indirect'] == 1]\n",
    "tem_ind = tem_ind[tem_ind['indirect'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5: accuracy\n",
    "print('PRECISION')\n",
    "print(obj_ind['correct'].mean())\n",
    "print(act_ind['correct'].mean())\n",
    "print(tem_ind['correct'].mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: group by model & make table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = [obj_de, act_de, tem_de]\n",
    "precision = [obj_ind, act_ind, tem_ind]\n",
    "titles = ['object', 'action', 'temporal']\n",
    "\n",
    "rec_df = pd.DataFrame()\n",
    "pre_df = pd.DataFrame()\n",
    "\n",
    "for de, ind, title in zip(recall, precision, titles):\n",
    "    rec = de.groupby(['model']).mean()['correct']\n",
    "    pre = ind.groupby(['model']).mean()['correct']\n",
    "    \n",
    "    \n",
    "    rec_df = rec_df.append(rec.transpose())\n",
    "    pre_df = pre_df.append(pre.transpose())\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "csv(rec_df, '5-recall')\n",
    "\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv(pre_df, '5-precison')\n",
    "\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = [obj_de, act_de, tem_de]\n",
    "precision = [obj_ind, act_ind, tem_ind]\n",
    "titles = ['object', 'action', 'temporal']\n",
    "\n",
    "rec_df = pd.DataFrame()\n",
    "pre_df = pd.DataFrame()\n",
    "\n",
    "for de, ind, title in zip(recall, precision, titles):\n",
    "    rec = de.groupby(['model', 'ans_type']).mean()['correct']\n",
    "    pre = ind.groupby(['model', 'ans_type']).mean()['correct']\n",
    "    \n",
    "    rec_df = rec_df.append(rec.transpose())\n",
    "    pre_df = pre_df.append(pre.transpose())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv(rec_df, '7-recall')\n",
    "\n",
    "rec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv(pre_df, '7-precison')\n",
    "\n",
    "pre_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cutoffhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most likely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostLikely(df, metric, ans_type=False):\n",
    "    metric_values = df[metric].unique()\n",
    "    \n",
    "    freq = pd.DataFrame()    \n",
    "    for val in sorted(metric_values):\n",
    "        data = df[df[metric] == val]\n",
    "        sort = data['answer'].value_counts(normalize=True)\n",
    "        print(val, round(sort[0] * 100, 2), data.shape[0])\n",
    "        \n",
    "        if ans_type:\n",
    "            b = data[data['ans_type'] == 'binary']\n",
    "            o = data[data['ans_type'] == 'open'] \n",
    "            \n",
    "            if b.shape[0] > 0:\n",
    "                sort = b['answer'].value_counts(normalize=True)\n",
    "                print('    binary', round(sort[0] * 100, 2))\n",
    "            \n",
    "            if o.shape[0] > 0:\n",
    "                sort = o['answer'].value_counts(normalize=True)\n",
    "                print('    open', round(sort[0] * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bal[bal['type'].isin(['objWhat', 'objLast', 'objFirst', 'objWhatGeneral'])]\n",
    "data = data[data['steps'] >= 4]\n",
    "\n",
    "data['Total'] = 1\n",
    "\n",
    "\n",
    "mostLikely(data, 'Total', ans_type=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(363261 + 363261 + 2394) / (177 + 43593 + 3618 + 363261 + 363261 + 2394)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bal[bal['type'].isin(['actLongest', 'actShortest', 'actFirst', 'actLast', 'actWhatAfterAll', 'actWhatBefore'])]\n",
    "data['Total'] = 1\n",
    "\n",
    "mostLikely(data, 'Total', ans_type=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of steps for binary vs open\n",
    "\n",
    "\n",
    "data = df[df['ans_type'] == 'open']\n",
    "data['novel_comp'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average number of steps for binary vs open\n",
    "\n",
    "t = 'nc_objrel'\n",
    "\n",
    "data = bal[bal['ans_type'] == 'binary']\n",
    "mostLikely(data, t, ans_type=False)\n",
    "\n",
    "\n",
    "data = bal[bal['ans_type'] == 'open']\n",
    "mostLikely(data, t, ans_type=False)\n",
    "\n",
    "\n",
    "data = bal\n",
    "mostLikely(data, t, ans_type=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['steps'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = bal[bal['structural'] == 'query']\n",
    "data.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g = pd.DataFrame()\n",
    "\n",
    "models = [p, hm, hc]\n",
    "metrics = [bl, ba, c, s]\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for epoch in range(1):\n",
    "            preds = getPreds('dataset', model, metric, epoch, glob=True)\n",
    "            preds['model'] = model\n",
    "            preds['metric'] = metric\n",
    "            preds['epoch'] = epoch\n",
    "            df_g = df_g.append(preds)\n",
    "            print('preds shape', preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_g = df_g[df_g['metric'] == 'balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostLikely(bal_g, 'global', ans_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostLikely(bal, 'structural', ans_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostLikely(bal, 'semantic', ans_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal['Total'] = 1\n",
    "mostLikely(bal, 'Total', ans_type=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal = df[df['metric'] == 'balanced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = bal.columns\n",
    "'correct' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal.groupby(['model','ans_type', 'steps']).mean().correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ml_steps_bin = {\n",
    "    1.0: 60.0,\n",
    "    2.0: 60.0,\n",
    "    3.0: 20.05,\n",
    "    4.0: 42.2,\n",
    "    5.0: 18.73,\n",
    "    6.0: 21.9,\n",
    "    7.0: 16.84,\n",
    "    8.0: 23.66,\n",
    "    9.0: 50.0,\n",
    "}\n",
    "\n",
    "ml_steps_open = {\n",
    "    1.0: 7.69,\n",
    "    2.0: 9.36,\n",
    "    3.0: 4.79,\n",
    "    4.0: 11.84,\n",
    "    5.0: 13.63,\n",
    "    6.0: 9.81,\n",
    "}\n",
    "ml_steps = {\n",
    "    1.0: 7.55,\n",
    "    2.0: 9.35,\n",
    "    3.0: 18.2,\n",
    "    4.0: 16.2,\n",
    "    5.0: 9.82,\n",
    "    6.0: 21.71,\n",
    "    7.0: 16.84,\n",
    "    8.0: 23.66,\n",
    "    9.0: 50.0,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcrn = bal[bal['model'] == 'hcrn']\n",
    "hcrn = hcrn[hcrn['ans_type'] == 'open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None): \n",
    "    print(hcrn.groupby(['ans_type', 'type']).count().Total_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "palettes = ['BuPu', 'PuOr_r', 'RdBu', 'RdBu_r', 'RdGy_r', 'Set3', 'afmhot', 'afmhot_r', 'seismic', 'seismic_r', 'tab20c', 'twilight_shifted', 'vlag_r']\n",
    "\n",
    "palettes_v2 = ['BrBG', 'BrBG_r', 'PuOr', 'PuOr_r', 'twilight_shifted', 'twilight_shifted_r']\n",
    "#for p in palettes:\n",
    "#    prin\n",
    "col = 'Paired'#'Dark2_r'#'vlag' # want it to be more distinct for all of them\n",
    "colors = sns.color_palette(col, 30)\n",
    "sns.palplot(sns.color_palette(col, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal = df[df['metric'] == 'blind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look = 'open'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStepsDF(model):\n",
    "    hcrn_df = bal[bal['model'] == model]\n",
    "    \n",
    "    #hcrn_df = hcrn_df[hcrn_df['ans_type'] == 'binary']\n",
    "    #hcrn_df = hcrn_df[(hcrn_df['steps'] != 1.0) & (hcrn_df['steps'] != 2.0) & (hcrn_df['steps'] != 9.0)]\n",
    "    #hcrn_df = hcrn_df[hcrn_df['ans_type'] == 'open']\n",
    "    #hcrn_df = hcrn_df[hcrn_df['ans_type'] == look]\n",
    "    \n",
    "    if False:\n",
    "        for s in [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]:\n",
    "            test_df = hcrn_df[hcrn_df['steps'] == s]\n",
    "            if test_df.shape[0] <= 10:\n",
    "                print('ignoring', s)\n",
    "                hcrn_df = hcrn_df[hcrn_df['steps'] != s]\n",
    "    #hcrn_df = hcrn_df[(hcrn_df['steps'] != 1.0)]\n",
    "    \n",
    "    hcrn_df = hcrn_df.groupby(['steps']).mean().correct\n",
    "    hcrn_df = hcrn_df.to_frame()\n",
    "\n",
    "    hcrn_df.reset_index(inplace=True)\n",
    "    hcrn_df = hcrn_df.rename(columns={'correct':'acc'})\n",
    "    return hcrn_df\n",
    "\n",
    "hcrn_df = getStepsDF('hcrn')\n",
    "hme_df = getStepsDF('hme')\n",
    "psac_df = getStepsDF('psac')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = 10\n",
    "plt.subplots(figsize=(size, size))\n",
    "\n",
    "hc = sns.regplot(x=\"steps\", y='acc', data=hcrn_df, color=colors[7], scatter_kws={'s':size*5})#, linewidth=lw)#int(len(colors) * .3)])\n",
    "hm = sns.regplot(x=\"steps\", y='acc', data=hme_df, color=colors[1], scatter_kws={'s':size*5})#, linewidth=lw)#int(len(colors) * .5)])\n",
    "p = sns.regplot(x=\"steps\", y='acc', data=psac_df, color=colors[9], scatter_kws={'s':size*5})#, linewidth=lw)#int(len(colors) * .7)])\n",
    "#y = ax.get_yticks()\n",
    "#y = [int(i * 100) for i in y]\n",
    "######p.set_yticklabels(y, size = size * 3)\n",
    "#ax.set_xticklabels([int(i) for i in ax.get_xticks()], size = size * 3)\n",
    "plt.title('Accuracy and Compositionality', fontsize=size*4)\n",
    "plt.title(look, fontsize=size*4)\n",
    "\n",
    "lab = ['HCRN', 'HME', \"PSAC\"]\n",
    "plt.xticks(fontsize=size*3)\n",
    "plt.yticks(fontsize=size*3)\n",
    "plt.xlabel('Compositional Steps', fontsize=size*4)\n",
    "plt.ylabel('Accuracy(%)', fontsize=size*4)\n",
    "\n",
    "p.legend(lab, fontsize='xx-large', frameon=True, labelspacing=.5, handlelength=2.0, prop={'size': size*3})#.texts[0].set_text(labels[0])\n",
    "#p.set(xticks=[i + 1 for i in range(10)])\n",
    "\n",
    "#ax.legend(lab, fontsize='xx-large', frameon=True, labelspacing=.5, handlelength=2.0, prop={'size': size*3})\n",
    "plt.savefig('../figures/dataset/accuracy_and_compo.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "   # bbox_to_anchor=(1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## percent above random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look = 'objFirst'\n",
    "look_type = 'type'\n",
    "ml_tp = ml_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if look != 'total':\n",
    "    bal2 = bal[bal[look_type] == look]\n",
    "sizes = bal2.groupby(['steps']).count()['Total_preds'].to_frame()\n",
    "sizes['Total_preds'] = sizes['Total_preds'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStepsDF(bal, look, look_type, model):\n",
    "    hcrn_df = bal[bal['model'] == model]\n",
    "    \n",
    "    #hcrn_df = hcrn_df[hcrn_df['ans_type'] == 'binary']\n",
    "    #hcrn_df = hcrn_df[(hcrn_df['steps'] != 1.0) & (hcrn_df['steps'] != 2.0) & (hcrn_df['steps'] != 9.0)]\n",
    "    #hcrn_df = hcrn_df[hcrn_df['ans_type'] == 'open']\n",
    "    if look != 'total':\n",
    "        hcrn_df = hcrn_df[hcrn_df[look_type] == look]\n",
    "    \n",
    "    if False:\n",
    "        for s in [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]:\n",
    "            test_df = hcrn_df[hcrn_df['steps'] == s]\n",
    "            if test_df.shape[0] <= 10:\n",
    "                print('ignoring', s)\n",
    "                hcrn_df = hcrn_df[hcrn_df['steps'] != s]\n",
    "    #hcrn_df = hcrn_df[(hcrn_df['steps'] != 1.0)]\n",
    "    \n",
    "    hcrn_df = hcrn_df.groupby(['steps']).mean().correct\n",
    "    hcrn_df = hcrn_df.to_frame()\n",
    "\n",
    "    hcrn_df.reset_index(inplace=True)\n",
    "    hcrn_df = hcrn_df.rename(columns={'correct':'acc'})\n",
    "    return hcrn_df\n",
    "\n",
    "#hcrn_df = getStepsDF('hcrn')\n",
    "#hme_df = getStepsDF('hme')\n",
    "#psac_df = getStepsDF('psac')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDF(steps):\n",
    "    data = []\n",
    "    for step in steps:\n",
    "        d = {'steps': step, 'ml': steps[step]}\n",
    "        data.append(d)\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "ml = toDF(ml_tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateDF(hcrn_df, ml, sizes):\n",
    "    hcrn_df['ml'] = ml['ml']\n",
    "    hcrn_df['aboveML'] = (hcrn_df['acc'] * 100) - hcrn_df['ml']\n",
    "    hcrn_df['sizes'] = sizes['Total_preds'].values\n",
    "    return hcrn_df\n",
    "\n",
    "#hcrn_df = updateDF(hcrn_df, ml)\n",
    "#hme_df = updateDF(hme_df, ml)\n",
    "#psac_df = updateDF(psac_df, ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandBySize(df, model):\n",
    "    bal_model = bal[bal['model'] == model]\n",
    "    for step in df['steps'].values:\n",
    "        size = bal_model[bal_model['steps'] == step].shape[0]\n",
    "        row = df[df['steps'] == step]\n",
    "        df = df.append([row]*size,ignore_index=True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hcrn_df = expandBySize(hcrn_df, 'hcrn')\n",
    "#hme_df = expandBySize(hme_df, 'hme')\n",
    "#psac_df = expandBySize(psac_df, 'psac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcrn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSteps(hcrn_df, hme_df, psac_df, y_axis, look):\n",
    "\n",
    "    size = 10\n",
    "    plt.subplots(figsize=(size, size))\n",
    "\n",
    "\n",
    "    hc = sns.regplot(x=\"steps\", y=y_axis, data=hcrn_df, color=colors[7], scatter_kws={'s':hcrn_df['sizes']})#, linewidth=lw)#int(len(colors) * .3)])\n",
    "    hm = sns.regplot(x=\"steps\", y=y_axis, data=hme_df, color=colors[1], scatter_kws={'s':hme_df['sizes']})#, linewidth=lw)#int(len(colors) * .5)])\n",
    "    p = sns.regplot(x=\"steps\", y=y_axis, data=psac_df, color=colors[9], scatter_kws={'s':psac_df['sizes']})#, linewidth=lw)#int(len(colors) * .7)])\n",
    "\n",
    "\n",
    "    #y = ax.get_yticks()\n",
    "    #y = [int(i * 100) for i in y]\n",
    "    ######p.set_yticklabels(y, size = size * 3)\n",
    "    #ax.set_xticklabels([int(i) for i in ax.get_xticks()], size = size * 3)\n",
    "    plt.title('Accuracy and Compositionality', fontsize=size*4)\n",
    "    plt.title(look, fontsize=size*4)\n",
    "\n",
    "    lab = ['HCRN', 'HME', \"PSAC\"]\n",
    "    plt.xticks(fontsize=size*3)\n",
    "    plt.yticks(fontsize=size*3)\n",
    "    plt.xlabel('Compositional Steps', fontsize=size*4)\n",
    "    plt.ylabel(y_axis, fontsize=size*4)\n",
    "\n",
    "    p.legend(lab, fontsize='xx-large', frameon=True, labelspacing=.5, handlelength=2.0, prop={'size': size*3})#.texts[0].set_text(labels[0])\n",
    "    #p.set(xticks=[i + 1 for i in range(10)])\n",
    "\n",
    "    #ax.legend(lab, fontsize='xx-large', frameon=True, labelspacing=.5, handlelength=2.0, prop={'size': size*3})\n",
    "    plt.savefig('../figures/dataset/accuracy_and_compo-%s.png' % look, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "       # bbox_to_anchor=(1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotNonAgg(hcrn_df, hme_df, psac_df, y_axis, look):\n",
    "\n",
    "    size = 10\n",
    "    plt.subplots(figsize=(size, size))\n",
    "\n",
    "    y_axis = 'correct'\n",
    "\n",
    "    hc = sns.regplot(x=\"steps\", y=y_axis, data=hcrn_df, color=colors[7], scatter_kws={'s':size*5})#, linewidth=lw)#int(len(colors) * .3)])\n",
    "    hm = sns.regplot(x=\"steps\", y=y_axis, data=hme_df, color=colors[1], scatter_kws={'s':size*5})#, linewidth=lw)#int(len(colors) * .5)])\n",
    "    p = sns.regplot(x=\"steps\", y=y_axis, data=psac_df, color=colors[9], scatter_kws={'s':size*5})#, linewidth=lw)#int(len(colors) * .7)])\n",
    "\n",
    "\n",
    "    #y = ax.get_yticks()\n",
    "    #y = [int(i * 100) for i in y]\n",
    "    ######p.set_yticklabels(y, size = size * 3)\n",
    "    #ax.set_xticklabels([int(i) for i in ax.get_xticks()], size = size * 3)\n",
    "    plt.title('Accuracy and Compositionality', fontsize=size*4)\n",
    "    plt.title(look, fontsize=size*4)\n",
    "\n",
    "    lab = ['HCRN', 'HME', \"PSAC\"]\n",
    "    plt.xticks(fontsize=size*3)\n",
    "    plt.yticks(fontsize=size*3)\n",
    "    plt.xlabel('Compositional Steps', fontsize=size*4)\n",
    "    plt.ylabel(y_axis, fontsize=size*4)\n",
    "\n",
    "    p.legend(lab, fontsize='xx-large', frameon=True, labelspacing=.5, handlelength=2.0, prop={'size': size*3})#.texts[0].set_text(labels[0])\n",
    "    #p.set(xticks=[i + 1 for i in range(10)])\n",
    "\n",
    "    #ax.legend(lab, fontsize='xx-large', frameon=True, labelspacing=.5, handlelength=2.0, prop={'size': size*3})\n",
    "    plt.savefig('../figures/dataset/accuracy_and_compo-%s.png' % look, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "       # bbox_to_anchor=(1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostLikelySteps(df, metric):\n",
    "    metric_values = df[metric].unique()\n",
    "    freq = {}\n",
    "    for val in sorted(metric_values):\n",
    "        data = df[df[metric] == val]\n",
    "        sort = data['answer'].value_counts(normalize=True)\n",
    "        freq[val] = round(sort[0] * 100, 2)\n",
    "        \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ml_tp = mostLikelySteps(data, 'steps')\n",
    "ml = toDF(ml_tp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualizeSteps(bal, look_type, look, y_axis):\n",
    "    # First, find most likely and put into right format\n",
    "    \n",
    "    if look != 'total':\n",
    "        data = bal[bal[look_type] == look]\n",
    "    else:\n",
    "        data = bal\n",
    "    \n",
    "    # checking without objWhat\n",
    "    #data = data[data['steps'] != 1]\n",
    "    #data = data[data['steps'] != 2]\n",
    "    #data = data[data['steps'] != 8]\n",
    "    \n",
    "    \n",
    "    if True:\n",
    "        for s in [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0]:\n",
    "            test_df = data[data['steps'] == s]\n",
    "            if test_df.shape[0] <= 30:\n",
    "                data = data[data['steps'] != s]\n",
    "    #hcrn_df = hcrn_df[(hcrn_df['steps'] != 1.0)]\n",
    "    \n",
    "    ml_tp = mostLikelySteps(data, 'steps')\n",
    "    ml = toDF(ml_tp)\n",
    "    \n",
    "    # Then get sizes\n",
    "    sizes = data.groupby(['steps']).count()['Total_preds'].to_frame()\n",
    "    #print(sizes)\n",
    "    sizes['Total_preds'] = sizes['Total_preds'] / 1000\n",
    "\n",
    "    # get df\n",
    "    if False:\n",
    "        hcrn_df = getStepsDF(data, look, look_type,'hcrn')\n",
    "        hme_df = getStepsDF(data, look, look_type,'hme')\n",
    "        psac_df = getStepsDF(data, look, look_type,'psac')\n",
    "    else: \n",
    "        hcrn_df = data[data['model'] == 'hcrn']\n",
    "        hme_df = data[data['model'] == 'hme']\n",
    "        psac_df = data[data['model'] == 'psac']\n",
    "    \n",
    "   # print(\"HCRN\")\n",
    "   # print(hcrn_df)\n",
    "    hcrn_df.at[0, 'acc'] = .67\n",
    "    hme_df.at[0, 'acc'] = .62\n",
    "    psac_df.at[0, 'acc'] = .63\n",
    "    \n",
    "    # update with ML\n",
    "    if False:\n",
    "        hcrn_df = updateDF(hcrn_df, ml, sizes)\n",
    "        hme_df = updateDF(hme_df, ml, sizes)\n",
    "        psac_df = updateDF(psac_df, ml, sizes)\n",
    "   # print(\"HCRN\")\n",
    "    #print(hcrn_df)\n",
    "    #print(\"HME\")\n",
    "    #print(hme_df)\n",
    "    #print(\"PSAC\")\n",
    "    #print(psac_df)\n",
    "    \n",
    "    # plot \n",
    "    #plotSteps(hcrn_df, hme_df, psac_df, y_axis, look)\n",
    "    plotNonAgg(hcrn_df, hme_df, psac_df, y_axis, look)\n",
    "    \n",
    "    \n",
    "visualizeSteps(bal, 'type', 'total', 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could also try just doing 0 and 1 to get size effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in templates:\n",
    "    visualizeSteps(bal, 'type', t, 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nine = bal[bal['steps'] == 9]\n",
    "\n",
    "nine.groupby(['model']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get most likely per template per steps. Then do above that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostLikelyTemplate(df, steps, template):\n",
    "    metric_values = df[metric].unique()\n",
    "    freq = {}\n",
    "    for val in sorted(metric_values):\n",
    "        data = df[df[metric] == val]\n",
    "        sort = data['answer'].value_counts(normalize=True)\n",
    "        freq[val] = round(sort[0] * 100, 2)\n",
    "        \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change most likely template function to be able to get mostly likely for each template for that amount of steps\n",
    "\n",
    "# Though is this not what I'm doing now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking out differences in copositional steps for open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcrn = bal[bal['model'] == 'hcrn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objExists = hcrn[hcrn['type'] == 'objExists']\n",
    "\n",
    "objExists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3 = objExists[objExists['steps'] == 3.0]\n",
    "\n",
    "obj3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify = hcrn[hcrn['structural'] == 'verify']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify.groupby(['indirect']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thoughts\n",
    "- why no 1 steps for objExists? That's weird. They seem to all have an indirect ref....\n",
    "- This is probably a balancing thing... though it should include for 'all' as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "short = hcrn[hcrn['type'] == 'actShortest']\n",
    "\n",
    "short.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking answer distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = 'dataset'\n",
    "model = 'hcrn'\n",
    "metric = 'balanced'\n",
    "epoch = '0'\n",
    "\n",
    "bal = getPreds(d_path, model, metric, epoch)\n",
    "bal = bal[bal['structural'] == 'choose']\n",
    "bal = bal.groupby('prediction').count().sort_values('Total_preds', ascending=False).rename_axis(\"prediction\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'blind'\n",
    "blind = getPreds(d_path, model, metric, epoch)\n",
    "blind = blind[blind['structural'] == 'choose']\n",
    "answer = blind.groupby('answer').count().sort_values('Total_preds', ascending=False).rename_axis(\"answer\").reset_index()\n",
    "\n",
    "blind = blind.groupby('prediction').count().sort_values('Total_preds', ascending=False).rename_axis(\"prediction\").reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.barplot(x=\"Total_preds\", y=\"answer\", data=answer, palette='Reds_r')\n",
    "ax.set(ylim=(0, 20000))\n",
    "sns.barplot(x=\"Total_preds\", y=\"prediction\", data=bal, palette='Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.barplot(x=\"Total_preds\", y=\"prediction\", data=blind, palette='Blues_r')\n",
    "ax.set(ylim=(0, 20000))\n",
    "ax = sns.barplot(x=\"Total_preds\", y=\"answer\", data=answer, palette='Reds_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.barplot(x=\"Total_preds\", y=\"answer\", data=answer, palette='Blues_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inQuestion(word, question):\n",
    "    if word in question:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'balanced'\n",
    "model = 'psac'\n",
    "epoch = 0\n",
    "bal = getPreds(d_path, model, metric, epoch)\n",
    "#bal = bal[bal['structural'] == 'compare']\n",
    "\n",
    "\n",
    "bal['predInQ'] = bal.apply(lambda x: inQuestion(x['prediction'], x['question']), axis=1)\n",
    "bal['ansInQ'] = bal.apply(lambda x: inQuestion(x['answer'], x['question']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'blind'\n",
    "blind = getPreds(d_path, model, metric, epoch)\n",
    "#blind = blind[blind['structural'] == 'compare']\n",
    "\n",
    "\n",
    "blind['predInQ'] = blind.apply(lambda x: inQuestion(x['prediction'], x['question']), axis=1)\n",
    "blind['ansInQ'] = blind.apply(lambda x: inQuestion(x['answer'], x['question']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind.groupby(['ansInQ', 'i_obj', 'i_temp', 'predInQ']).count()[['Total_preds', 'type']]\n",
    "blind.groupby(['predInQ']).count()[['Total_preds', 'type']]\n",
    "\n",
    "#blind2 = blind[blind['structural'] == 'compare']#blind[(blind['type'] == 'actTime') | (blind['type'] == 'relTime') | (blind['type'] == 'objTime') ] #(bal['type'] == 'actLengthLongerChoose') | \n",
    "blind2 = blind\n",
    "blind2 = blind2[(blind2['type'] == 'actLengthLongerChoose') |(blind2['type'] == 'actLengthShorterChoose')]\n",
    "blind.groupby(['type', 'predInQ']).count()[['correct']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#bal.groupby(['ansInQ', 'i_obj', 'i_temp', 'predInQ']).count()[['Total_preds', 'type']]\n",
    "#bal2 = bal[bal['structural'] == 'compare']#bal[(bal['type'] == 'actTime') | (bal['type'] == 'relTime') | (bal['type'] == 'objTime') ] #(bal['type'] == 'actLengthLongerChoose') | \n",
    "bal2 = bal\n",
    "bal2 = bal2[(bal2['type'] == 'actLengthLongerChoose') |(bal2['type'] == 'actLengthShorterChoose')]\n",
    "bal2.groupby(['type', 'predInQ']).count()[['correct']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so -- it is the 3 times, but mostly Length Choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50 / 3258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: I could use the \"or\" word to find this out in more detail, but that would take a while\n",
    "\n",
    "5132 with an indirect obj, no indirect templ, and the answer is in the question\n",
    "    - These are the only ones where we're certain it's the only one in the question to guess\n",
    "    \n",
    "27403 with no indirect object at all\n",
    "    - so then sure both possible answers are in the question\n",
    "\n",
    "30310 with indirect object, indirect templ, and answer is in the question\n",
    "    - These are unclear. it could be that the answer is the only one in the question, and the indirect object is the other choice. Or, it could be that the indirect object is in the temporal localization (because it is indirect in an action). However, most are probably where it's only the one answer\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8303 + 19100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_temp = bal[(bal['i_temp'] == 0)]\n",
    "no_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_indirect.groupby(['ansInQ', 'i_obj', 'type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "27403 / 94436"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "blind['ansInQ'] = blind.apply(lambda x: inQuestion(x['answer'], x['question']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind['bothInQ'] = blind['ansInQ'] + blind['predInQ']\n",
    "blind.groupby(['bothInQ', 'correct']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal['bothInQ'] = bal['ansInQ'] + bal['predInQ']\n",
    "bal.groupby(['bothInQ', 'correct']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction distr for both\n",
    "\n",
    "blind.groupby('prediction').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicted answers within the video?\n",
    "\n",
    "Of the choose questions when blind, it often relies on the quesitons. Lets see if when it can see the video, it uses that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the obj and actions in each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleLoad(path):\n",
    "    file = open(path, 'rb')\n",
    "    info = pickle.load(file)\n",
    "    file.close()\n",
    "    return info\n",
    "\n",
    "train_stsgs = pickleLoad('../data/training_camera_ready_stsgs.pkl')\n",
    "test_stsgs = pickleLoad('../data/testing_camera_ready_stsgs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENG = pickleLoad('../data/eng.pkl')\n",
    "PP = pickleLoad('../data/pres_part.pkl')\n",
    "IDX = pickleLoad('../data/idx.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = {}\n",
    "for v_id in list(test_stsgs):\n",
    "    objs = test_stsgs[v_id]['obj_names'].copy()\n",
    "    objs2 = []\n",
    "    for i, obj in enumerate(objs):\n",
    "        objs2.append(ENG[obj])\n",
    "    acts = test_stsgs[v_id]['act_names'].copy()\n",
    "    acts2 = []\n",
    "    for i, act in enumerate(acts):\n",
    "        acts2.append(ENG[act])\n",
    "    items[v_id] = objs\n",
    "    items[v_id] += list(objs2)\n",
    "    items[v_id] += list(acts)\n",
    "    items[v_id] += list(acts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in items:\n",
    "    print(items[i])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreds(d_path, model, metric, epoch):\n",
    "    preds_path = '../exports/%s/results/organized/preds_%s_%s_%s-preds.csv' % (d_path, model, metric, epoch)\n",
    "    return pd.read_csv(preds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inQuestion(word, question):\n",
    "    if word in question:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def inVideo(word, q_id):\n",
    "    if word not in IDX:\n",
    "        return -1\n",
    "    idx = IDX[word] \n",
    "    video_id = q_id[:5]\n",
    "    \n",
    "    if idx in items[video_id]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'balanced'\n",
    "model = 'psac'\n",
    "epoch = 0\n",
    "bal = getPreds(d_path, model, metric, epoch)\n",
    "#bal = bal[bal['structural'] == 'choose']\n",
    "\n",
    "\n",
    "bal['predInQ'] = bal.apply(lambda x: inQuestion(x['prediction'], x['question']), axis=1)\n",
    "bal['predInV'] = bal.apply(lambda x: inVideo(x['prediction'], x['id']), axis=1)\n",
    "bal['ansInV'] = blind.apply(lambda x: inVideo(x['answer'], x['id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'blind'\n",
    "blind = getPreds(d_path, model, metric, epoch)\n",
    "#blind = blind[blind['structural'] == 'choose']\n",
    "\n",
    "\n",
    "blind['predInQ'] = blind.apply(lambda x: inQuestion(x['prediction'], x['question']), axis=1)\n",
    "blind['predInV'] = blind.apply(lambda x: inVideo(x['prediction'], x['id']), axis=1)\n",
    "blind['ansInV'] = blind.apply(lambda x: inVideo(x['answer'], x['id']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal2 = bal[bal['predInQ'] == 0]\n",
    "bal2.groupby(['predInV']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blind2 = blind[blind['predInQ'] == 0]\n",
    "blind2.groupby(['predInV']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out what's wrong with PSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine questions that get right in blind not in bal and vice versa\n",
    "\n",
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal['bal_pred'] = bal['prediction']\n",
    "bal['bal_correct'] = bal['correct']\n",
    "blind['blind_pred'] = blind['prediction']\n",
    "blind['blind_correct'] = blind['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bal_pred = bal[['bal_pred', 'bal_correct', 'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = blind.merge(bal_pred, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo['num_correct'] = combo['blind_correct'] + combo['bal_correct']\n",
    "combo['only_blind_bool'] = (combo['blind_correct'] == 1) & (combo['bal_correct'] == 0)\n",
    "combo['only_blind'] = combo['only_blind_bool'].apply(lambda x: 1 if x else 0)\n",
    "combo['only_bal_bool'] = (combo['bal_correct'] == 1) & (combo['blind_correct'] == 0)\n",
    "combo['only_bal'] = combo['only_bal_bool'].apply(lambda x: 1 if x else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.groupby(['structural']).mean()[['only_blind', 'only_bal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, from above, verify and logic are about the same. only care about other 3\n",
    "\n",
    "query and compare seem like bigger deals. start with query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo2 = combo[combo['structural'] == 'query']\n",
    "\n",
    "combo2.groupby('type').mean()[['only_blind', 'only_bal']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from above, objFirst, objLast, objWhat, and objWhatgeneral are doing better with blind\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getPerc(num, total):\n",
    "    return round(num / total * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TOTAL')\n",
    "print('both Correct: ', getPerc(143410, 606407))\n",
    "print('both Incorrect: ', getPerc(268687, 606407))\n",
    "print('only Blind: ', getPerc(107708, 606407))\n",
    "print('only Bal: ', getPerc(86602, 606407))\n",
    "print()\n",
    "print(\"BINARY\")\n",
    "print('both Correct: ', getPerc(89827, 309250))\n",
    "print('both Incorrect: ', getPerc(95403, 309250))\n",
    "print('only Blind: ', getPerc(66644, 309250))\n",
    "print('only Bal: ', getPerc(57376, 309250))\n",
    "print()\n",
    "print(\"OPEN\")\n",
    "print('both Correct: ', getPerc(53583, 297157))\n",
    "print('both Incorrect: ', getPerc(173284, 297157))\n",
    "print('only Blind: ', getPerc(41064, 297157))\n",
    "print('only Bal: ', getPerc(29226, 297157))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^^^ Not helpful because all slightly better for blind..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check distributions of this vs old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_path and group\n",
    "d_path = 'dataset'\n",
    "group = 'test'\n",
    "\n",
    "# Getting dataframe of questions\n",
    "path = '../exports/%s/other_formats/%s-%s-agqa.csv'\n",
    "path_g = '../exports/%s/other_formats/%s-%s-agqa-global.csv'\n",
    "df_qs = pd.read_csv(path % (d_path, group, 'balanced'))\n",
    "df_qs_g = pd.read_csv(path_g % (d_path, group, 'balanced'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = 'dataset_camera_ready'\n",
    "df_old_qs = pd.read_csv(path % (d_path, group, 'balanced'))\n",
    "df_old_qs_g = pd.read_csv(path_g % (d_path, group, 'balanced'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_old_qs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 'old'\n",
    "step = 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotType(tp, step):\n",
    "    gb = ['type']\n",
    "    title = \"%s-%s\" % (tp, str(step))\n",
    "    \n",
    "    if tp == 'new':\n",
    "        df = df_qs\n",
    "        pal = 'Reds'\n",
    "    elif tp == 'old':\n",
    "        df = df_old_qs\n",
    "        pal = 'Blues'\n",
    "    if type(step) != str:\n",
    "        df2 = df[df['steps'] == step]\n",
    "    else:\n",
    "        df2 = df\n",
    "\n",
    "        \n",
    "    xaxis = 'correct'\n",
    "    yaxis = 'type'\n",
    "    \n",
    "    old = df2.groupby(gb).mean()\n",
    "    old = old.reset_index()\n",
    "    old = old.sort_values(xaxis)\n",
    "    \n",
    "    if old.shape[0] == 0:\n",
    "        print(tp, step, 'does not have any data')\n",
    "        return\n",
    "\n",
    "    # plot\n",
    "    size = old.shape[0]\n",
    "    plt.figure(figsize=(size* 2, size*1.5))\n",
    "    sns.barplot(x=xaxis, y=yaxis, data=old, palette=pal)\n",
    "    plt.title(title, size=size*4)\n",
    "    plt.xticks(fontsize=size*3)\n",
    "    plt.yticks(fontsize=size*3)\n",
    "    plt.xlabel(xaxis, fontsize=size*4)\n",
    "    plt.ylabel(yaxis, fontsize=size*4)\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for step in range(10):\n",
    "    for tp in ['old', 'new']: \n",
    "        print(tp, step)\n",
    "        plotType(tp, step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('steps').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../exports/dataset/all/test/0F7LW.txt') as f:\n",
    "    qa = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new = {}\n",
    "for q in qa:\n",
    "    for tp in ['indirects', 'direct_time']:\n",
    "        indir = qa[q]['metrics'][tp]\n",
    "\n",
    "        i = \"\"\n",
    "\n",
    "        for ind in indir:\n",
    "            i += str(ind)\n",
    "            i += '-'\n",
    "        new_tp = tp + \"_str\"\n",
    "        qa[q][new_tp] = i\n",
    "    \n",
    "    \n",
    "    for tp in ['attributes', 'metrics']:\n",
    "        for i in qa[q][tp]:\n",
    "            qa[q][i] = qa[q][tp][i]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(qa).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[df['type'] == 'objExists']\n",
    "#df2 = df2[df2['indirects_str'] == 'True-False-False-True-']\n",
    "#df2 = df2[df2['steps'] == 2.0]\n",
    "\n",
    "df2.groupby(['steps']).count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.indirects_str.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = df2.question.values\n",
    "for i in qs:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_time = df.direct_time_str."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checking answer ditsrs and stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_qs[(df_qs['answer'] =='yes') | (df_qs['answer'] =='no')]\n",
    "\n",
    "#x = x[x['local'] == 'before-after-o12-c000-all-']\n",
    "\n",
    "x.groupby(['local', 'answer']).count().sort_values('question')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts = df_qs.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x), x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "by_loc = {}\n",
    "\n",
    "for q in dicts:\n",
    "\n",
    "    loc = q['program']#q['local']\n",
    "    a = q['answer']\n",
    "    if a not in ['before', 'after']:\n",
    "        continue\n",
    "\n",
    "    if loc not in by_loc:\n",
    "        by_loc[loc] = {\n",
    "            'before': 0,\n",
    "            'after': 0\n",
    "        }\n",
    "\n",
    "    by_loc[loc][a] += 1\n",
    "        \n",
    "        \n",
    "\n",
    "for loc in by_loc:\n",
    "    x = by_loc[loc]\n",
    "    b = x['before']\n",
    "    a = x['after']\n",
    "    \n",
    "    if b != a: \n",
    "        print(b, a)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qs['indirect_count'] = df_qs['i_obj'] + df_qs['i_rel'] + df_qs['i_act'] + df_qs['i_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.groupby(['steps', 'answer']).count().sort_values('question', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "by_loc = {}\n",
    "\n",
    "for q in dicts:\n",
    "\n",
    "    loc = q['local']\n",
    "    a = q['answer']\n",
    "    if a not in ['yes', 'no']:\n",
    "        continue\n",
    "\n",
    "    if loc not in by_loc:\n",
    "        by_loc[loc] = {\n",
    "            'yes': 0,\n",
    "            'no': 0\n",
    "        }\n",
    "\n",
    "    by_loc[loc][a] += 1\n",
    "        \n",
    "        \n",
    "\n",
    "for loc in by_loc:\n",
    "    x = by_loc[loc]\n",
    "    b = x['yes']\n",
    "    a = x['no']\n",
    "    \n",
    "    if b != a: \n",
    "        print(b, a)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# still tryinbg to figure out objTime but this time wiht preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "models = [p, hm, hc]\n",
    "metrics = [bl, ba, c, s]\n",
    "\n",
    "for model in models:\n",
    "    for metric in metrics:\n",
    "        for epoch in range(1):\n",
    "            data = {\n",
    "                'model': model,\n",
    "                'metric': metric,\n",
    "                'epoch': epoch,\n",
    "            }\n",
    "    \n",
    "            stats_path = '../../exports/%s/results/organized/preds_%s_%s_%s-preds.json' % (d_path, model, metric, epoch)\n",
    "            if pathExists(stats_path):\n",
    "                print(stats_path)\n",
    "                with open(stats_path, 'rb') as f:\n",
    "                    stats = json.load(f)\n",
    "                    \n",
    "                data['size'] = stats['size']\n",
    "                perc = stats['perc_correct']\n",
    "                \n",
    "                for i in perc:\n",
    "                    if False:\n",
    "                        if 'tp' in i:\n",
    "                            to_del = []\n",
    "                            to_add = []\n",
    "                            print(i)\n",
    "                            for cat in perc[i]:\n",
    "                                new_cat = '%s-%s' % (i, cat)\n",
    "                                #perc[i][new_cat] = perc[i][cat]\n",
    "\n",
    "                                to_del.append(cat)\n",
    "                                to_add.append((new_cat, perc[i][cat]))\n",
    "                            for cat in to_del:\n",
    "                                del perc[i][cat]\n",
    "                            for new_cat, item in to_add:\n",
    "                                perc[i][new_cat] = item\n",
    "\n",
    "                    if False:\n",
    "                        for i in perc:\n",
    "                            print(i)\n",
    "                            if type(perc[i]) == dict:\n",
    "                                for j in perc[i]:\n",
    "                                    print('.  ', j)\n",
    "                    data = updateDic(perc[i], data, i)\n",
    "                    \n",
    "                    \n",
    "                df_list.append(data)\n",
    "            else:\n",
    "                print(\"NO: %s\" % stats_path)\n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_path = 'dataset'\n",
    "model = 'hcrn'\n",
    "metric = 'blind'\n",
    "epoch = 0\n",
    "\n",
    "preds = pd.read_csv('../../exports/%s/results/organized/preds_%s_%s_%s-preds.csv' % (d_path, model, metric, epoch))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds['indirect_count'] = preds['i_obj'] + preds['i_rel'] + preds['i_act'] + preds['i_temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba = preds[(preds['answer'] == 'before') | (preds['answer'] == 'after')]\n",
    "\n",
    "#ba = ba[ba['local'] == 'before-after-o12-c001-all-']\n",
    "\n",
    "ba.groupby(['indirect_count','AGQA_ans']).count()#.sort_values('question', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba['fake_ans'] = 'after'\n",
    "\n",
    "ba['fake_correct'] = ba['fake_ans'] == ba['AGQA_ans']\n",
    "\n",
    "\n",
    "\n",
    "ba.groupby(['fake_correct']).count().sort_values('question', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things I know -- HCRN\n",
    "- prediciting before twice as often as after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/stsgs/test_stsgs.pkl', 'rb') as f:\n",
    "    test_stsgs = pickle.load(f)\n",
    "    \n",
    "with open('../../data/stsgs/train_stsgs.pkl', 'rb') as f:\n",
    "    train_stsgs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inCat(q):\n",
    "    \n",
    "    if q['metrics']['indirects'][0] and q['metrics']['indirects'][2]:#.count(True) != 0:\n",
    "        return True\n",
    "                \n",
    "    if q['metrics']['indirects'][0] and not q['metrics']['indirects'][2]:#.count(True) != 0:\n",
    "        return True\n",
    "        \n",
    "    if not q['metrics']['indirects'][0] and q['metrics']['indirects'][2]:#.count(True) != 0:\n",
    "        return True\n",
    "        \n",
    "    if q['metrics']['indirects'].count(True) != 0:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "            \n",
    "\n",
    "stsgs = train_stsgs\n",
    "group = 'train'\n",
    "\n",
    "by_loc = {}\n",
    "num_accounted = 0\n",
    "num_not_accounted = 0\n",
    "total_ba = 0\n",
    "tot_test = 0\n",
    "objTime_train = []\n",
    "\n",
    "stuff = {\n",
    "    0: [],\n",
    "    1: [], \n",
    "    2: [], \n",
    "    3: [], \n",
    "    4: [],\n",
    "}\n",
    "\n",
    "for i in stsgs:\n",
    "    try:\n",
    "        with open('../../exports/dataset/balanced - main dataset/%s/%s.txt' % (group, i), 'rb') as f:\n",
    "            QA = json.load(f)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    for q_id in QA:\n",
    "        q = QA[q_id]\n",
    "        \n",
    "        loc = q['local']\n",
    "        a = q['answer']\n",
    "        if a not in ['before', 'after']:\n",
    "            continue\n",
    "            \n",
    "        if q['metrics']['indirects'][0] and q['metrics']['indirects'][2]:#.count(True) != 0:\n",
    "            stuff[0].append(q_id)\n",
    "            continue\n",
    "\n",
    "        elif q['metrics']['indirects'][0] and not q['metrics']['indirects'][2]:#.count(True) != 0:\n",
    "            stuff[1].append(q_id)\n",
    "            continue\n",
    "\n",
    "        elif not q['metrics']['indirects'][0] and q['metrics']['indirects'][2]:#.count(True) != 0:\n",
    "            stuff[2].append(q_id)\n",
    "            continue\n",
    "\n",
    "        elif q['metrics']['indirects'].count(True) != 0:\n",
    "            stuff[3].append(q_id)\n",
    "            \n",
    "        else:\n",
    "            stuff[4].append(q_id)\n",
    "            \n",
    "        objTime_train.append(q)\n",
    "        if loc not in by_loc:\n",
    "            by_loc[loc] = {\n",
    "                'before': 0,\n",
    "                'after': 0\n",
    "            }\n",
    "            \n",
    "        by_loc[loc][a] += 1\n",
    "        \n",
    "        \n",
    "#if False:\n",
    "equal = []\n",
    "\n",
    "for loc in by_loc:\n",
    "    x = by_loc[loc]\n",
    "    b = x['before']\n",
    "    a = x['after']\n",
    "    #if inCat(q):\n",
    "    #    tot_test += b + a\n",
    "    #    equal.append()\n",
    "    \n",
    "    equal.append('before-after-%s-all-' % loc)\n",
    "    if b != a: \n",
    "        \n",
    "        continue\n",
    "    else:\n",
    "        continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stuff:\n",
    "    print(i, len(stuff[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loc = ba#[ba['local'].apply(lambda x: x in equal)] #preds['local'] == 'before-after-o15-c065-all-']\n",
    "loc = loc[(loc['i_obj']  == 0) & (loc['i_act']  == 0)]\n",
    "#loc['isCat'] = loc.apply(inCat)\n",
    "\n",
    "# Permanently changes the pandas settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    " \n",
    "# All dataframes hereafter reflect these changes.\n",
    "display(loc.groupby(['prediction', 'AGQA_ans']).count())\n",
    " \n",
    "print('**RESET_OPTIONS**')\n",
    " \n",
    "# Resets the options\n",
    "pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(11801 + 19810) / (11801 + 2608 + 10617 + 19810)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AccEqual: 2007\n",
    "More Before: 15274\n",
    "More After: 15469\n",
    "Only Before: 14591\n",
    "Only After: 14734uracies by indirect reference (test set)\n",
    "\n",
    "AB = predicted After, ground truth answer is Before\n",
    "\n",
    "- Format: (AA + BB) / (AA + AB + BA + BB)\n",
    "\n",
    "- No indirect: (445 + 3868) / (445 + 430 + 3928 + 3868) 49.74\n",
    "\n",
    "- Any indirect: (11283 + 19104) / (11283 + 2488 + 10309 + 19103) 70.36\n",
    "\n",
    "- Only indirect obj: (11339 + 15830) / (11339 + 2174 + 6640 + 15830) 75.50\n",
    "\n",
    "- Only indirect act: (45) / (33 + 45) 57.69\n",
    "\n",
    "- Indirect obj and act: (17 + 67) / (17 + 4 + 16 + 67) 80.7\n",
    "\n",
    "- All questions: (11801 + 19810) / (11801 + 2608 + 10617 + 19810) 70.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.shape, 11801 + 2608 + 10617 + 19810, 17 + 4 + 16 + 67 + 33 + 45 + 11339 + 2174 + 6640 + 15830 + 445 + 430 + 3928 + 3868\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OK this is for non-indirect in test set\n",
    "\n",
    "- so when no indirect objects or acts, it guesses more before but it still gets about 50%\n",
    "    - Unequal in training: (340 + 3190) / (340 + 319 + 3195 + 3190) 0.5011\n",
    "    - Equal in training: (78 + 573) / (78 + 78 + 620 + 573) 0.4825\n",
    "- when just indirect objects: \n",
    "    - Unequal in training: (352 + 3194) / (352 + 329 + 3199 + 3194) 0.5012\n",
    "    - Equal in training: (66 + 569) / (66 + 68 + 616 + 569) 0.4814\n",
    "- when just indirect actions:\n",
    "    - Unequal in training: (72 + 766) / (72 + 68 + 694 + 766) 0.5237\n",
    "    - Equal in training: (346 + 2997) / (346 + 329 + 3121 + 2997) 0.4921\n",
    "- when both indirect object and indirect action\n",
    "    - Unequal in training: (62 + 662) / (62 + 62 + 614 + 662) 0.5171\n",
    "    - Equal in training: (356 + 3101) / (356 + 335 + 3201 + 3101) 0.4943\n",
    "    \n",
    "    \n",
    "    \n",
    "The rest are maybe things that did not occur in the thingy?\n",
    "OH I think all these numbers were for test where there is no like... indirect anything?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(62 + 662) / (62 + 62 + 614 + 662)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cats = 340 + 319 + 3195 + 3190 + 78 + 78 + 620 + 573 + 352 + 329 + 3199 + 3194 + 66 + 68 + 616 + 569 + 72 + 68 + 694 + 766 + 346 + 329 + 3121 + 2997 + 356 + 335 + 3201 + 3101 + 62 + 62 + 614 + 662\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(objTime_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in stuff:\n",
    "    print(i, len(stuff[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[preds['answer'] == 'after'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Equal: 2007\n",
    "More Before: 15274\n",
    "More After: 15469\n",
    "Only Before: 14591\n",
    "Only After: 14734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2007 + 15274 + 15469 + 14591 + 14734"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
